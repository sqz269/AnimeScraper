; API CROSS-REFERENCE: THE DETAILS OF API CAN BE FOUND IN PIXIVWEBAPIREVERSE.MD AT /DOCS

; multiple values can be stored in a file and point to the file by doing:
; file<{encoding}><{separator}>: {path}
; for example: file<utf-8><\n>: myLeastFavoriteArtists.txt
; will read myLeastFavoriteArtists.txt with utf-8 encoding and split the content line by line (\n)
; to not split the file content using separator use None in separator field. ex: file<utf-8><None>: asdf.txt

[QUERY]
; List of configurations that will be directly added to search query,
; More of this filled the faster the scraper will run
TAGS_QUERY =
; {string(space separated)} REQUIRED
; Tags that will be present in the search query, returns result base on this tag
; API Cross-Reference: URL Path & word

TAGS_EXCLUDE_QUERY =
; {string(space separated)}
; make the result excluded from this tag. present in Query
; API Cross-Reference: URL Path & word

SEARCH_MODE = s_tag
; {predefined-string} REQUIRED
; Search Mode: s_tag_full, s_tag, s_tc
; API Cross-Reference: s_mode

SUBMISSION_TYPE = all
; {predefined-string} REQUIRED
; Only scrape a very certain type of illustrations
; available types: all, illust_and_ugoira, illust, manga, ugoira
; API Cross-Reference: type

RATING = all
; {predefined-string}
; available ratings: all, safe, r18
; API Cross-Reference: mode

; leave below fields empty to ignore
HEIGHT_MIN =
; {int}
; The minimal height of the image for it to be considered
; API Cross-Reference: hlt

WIDTH_MIN =
; {int}
; The minimal width dimension of the image for it to be considered
; API Cross-Reference: wlt

HEIGHT_MAX =
; {int}
; Any image above this height will not be considered
; API Cross-Reference: hgt

WIDTH_MAX =
; {int}
; Any image above this width will not be considered
; API Cross-Reference: wgt

ORIENTATION =
; {float (-1~1)}
; API Cross-Reference: ratio

TOOL =
; {string}
; API Cross-Reference: tool

[REQUIREMENTS]
TAGS_EXCLUDE =
; {string(comma separated)}
; Always don't scrape this tag
; NOT Present in query

TAGS_BYPASS =
; {string(comma separated)}
; Always scrape illustrations with this tag
; NOT Present in query

NON_QUERY_TAG_MATCH_MODE =
; {predefined-string} REQUIRED
; Matching Mode: absolute, contains

; below settings cannot be blank
PAGE_COUNT_MIN = 0
; {int} REQUIRED
; The submitted illustrations must contain this amount of picture
; Set it to 0 for any page count

PAGE_COUNT_MAX = 0
; {int} REQUIRED
; The submitted illustrations must not contain this amount of picture or above
; Set it to 0 for any page count

VIEW_MIN = 0
; {int} REQUIRED
; minimal views in order for the illustration to be scraped

AVG_VIEW_PER_DAY = 0
; {float} REQUIRED
; NOT IMPLEMENTED
; Minimal views per 24 hours

VIEW_BOOKMARK_RATIO = 0
; {int} REQUIRED
; The ratio of views per bookmark in order for the illustration to be scraped
; ratio is calculated using floor(view count / bookmark count)

BOOKMARK_MIN = 400
; {int} REQUIRED
; minimal bookmarks in order for the illustration to be scraped

AVG_BOOKMARK_PER_DAY = 6
; {float} REQUIRED
; Minimal book marks per 24 hours
; Mathematical expression available [Experimental]
; Available variables: [t = number of days since posted]
; PRESET EXPRESSION: 0.9**(0.1*(t-300))+2
; DESMOS FRIENDLY VERSION: N\left(t\right)=0.9^{(0.1\cdot(t-300))+2}
; [Hint: Graph it on https://www.desmos.com/calculator to see the effect]

VIEW_BOOKMARK_RATIO_BYPASS = 1000
; {float} REQUIRED
; Bypass view/bookmark ratio and avg bookmark per day if total bookmarks reach this amount

; Below settings can be left blank
TITLE_INCLUDE =
; {string(comma separated)}
; title must include certain words

TITLE_EXCLUDE =
; {string(comma separated)}
; certain words must not be present in the title

USER_EXCLUDE =
; {string(comma separated)}
; excludes a work from scraped by a user even if their works meet the basic requirements

USER_INCLUDE =
; {string(comma separated)}
; always scrape the work of this user even if their works might not meet the basic requirements

DESCRIPTION_EXCLUDE =
; {string}

IGNORE_BOOKMARKED = false
; {bool}
; true if you want to ignore submissions you've already bookmarked

[Range]
START_PAGE = 1
; {int} REQUIRED
END_PAGE = 30
; {int} REQUIRED

REVERSE_GENERATED_URL = false
; {bool}
; reverses the list of url generated by generate_url function
; to start the scrape at the end page first

; DEPRECATED, USE OPTION: REVERSE_GENERATED_URL INSTEAD
; END_PAGE_FIRST = true
; {bool}
; start from the end page first to reduce duplicates

SORTED_BY = date_d
; {predefined-string} REQUIRED
; Sorting image using this order
; available fields are: date, date_d
; API Cross-Reference: order

SUBMISSION_BEFORE =
; {string(time-stamp)}
; Only get image that is submitted before this date
; Timestamp example: 2020-03-16 (YYYY-MM-DD)
; API Cross-Reference: ecd

SUBMISSION_AFTER =
; {string(time-stamp)}
; Only get image that is submitted after this date
; Timestamp example: 2020-03-16 (YYYY-MM-DD)
; API Cross-Reference: scd

[Authorization]
PHPSESSID =
; {string} REQUIRED, from session cookie
; this is used for getting search API response and image information
; getting your PHPSESSID, login to pixiv in browser, after logging in
; open the developer console (usually f12 or right click select the option "Inspect Element") in the browser on the pixiv's webpage
; for chrome: on dev tools, go to Application -> Storage -> Cookies and copy paste the value of PHPSESSID
; for firefox: on dev tools, go to Storage -> Cookies -> www.pixiv.net, copy paste the value of PHPSESSID
; PHPSESSID should look something like  00000000_A0A0AAAAA00000AAAAAA000000000A00

[Output]
SAVE_PATH = .
; {string(path like)}
; Save scraped image to this READABLE/WRITEABLE directory

MASTER_DIRECTORY_NAME_STRING = pixiv page {start_page}-{end_page} {tags_query}
; {string}
; Any settings that are present in this file, but all lower cased
; for example BOOKMARK_MIN will become {bookmark_min},
; DO NOT PUT SPECIAL CHARACTERS

FILENAME_STRING = {image_id}-{image_bookmarks}-{image_likes}-{image_type}-{img_index}.{image_extension}
; {string}
; Available Fields everything below with one extra
;                   {img_index} // THIS HAVE TO BE INCLUDED IF YOU DON"T WANT IMAGES TO BE OVERWRITTEN

CSV_ENTRY_STRING = {image_title},{image_id},{image_tags},{image_bookmarks},{image_views},{image_avg_bookmark_perday},{image_view_bookmark_ratio},{image_likes},{image_comments},{image_width},{image_height}
; {string}
; Available fields: {image_id},      // IllustId
;                   {image_tags},   // Title of the illust
;                   {image_extension},    // Submission type
;                   {image_title},    // Tags will be look like [tags 1, tags2, tags3] in one field
;                   {image_type},
;                   {image_date},
;                   {image_uploader_id},
;                   {image_uploader_name}
;                   {image_width}
;                   {image_height}
;                   {image_page_count}
;                   {image_bookmarks}
;                   {image_avg_bookmark_perday}
;                   {image_view_bookmark_ratio}
;                   {image_views}
;                   {image_likes}     // number of likes
;                   {image_comments}  // number of comments
;                   {image_is_original}

[Advanced]
MAX_CONCURRENT_THREAD = 3
; {int}
; Max thread that will be used to scrape the images, each page will have their individual threads

DOWNLOAD_DELAY = 1.4
; {float}
; Wait this seconds before starting downloading the image

DELAY_START = 0

READ_IMG_INFO_DELAY = 0
; {float}
; Wait this seconds before reading the next images information

; WAIT_AFTER_MAX_REQUEST = 120
; {int}
; Wait to retry after a the max request has been send to the server and it
; issued a very short lived ban on our address

COLLECT_DATA_ONLY = false
; {boolean}
; True if the scraper will only write image's data without downloading the image
; useful if you want to quickly view the top raking image w/o premium

USER_AGENT = Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4018.0 Safari/537.36

IMAGE_SIZE = original
; {predefined-string}
; square_medium, medium, large, original

FLUSH_CSV_IMMINENTLY = false
; {bool}
; True to Imminently save csv file using .flush(), reduces performances
; False to save the written file only when the scraping is completely finished

USE_SUBMISSION_SPECIFIC_DIRECTORY = true

THREAD_NAME_PREFIX = pixiv_slow

[Cleanup]
MERGE_FILE = True
; {boolean}
MERGE_FILE_KEEP_SEPARATE = True
; {boolean}
COMPRESS = False
; {boolean}

[Logging]
LOGGER_FILE = WARNING
; {predefined-string}
LOGGER_STDOUT = DEBUG
; {predefined-string}

LOGGER_NAME = pixiv
; Available logging levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
;                           Sorted in order from the MOST info to LEAST
